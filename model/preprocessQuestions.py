import nltk
import pickle
import tensorflow as tf

nltk.download('wordnet')
nltk.download('omw-1.4')
nltk.download('stopwords')

from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
from keras_preprocessing.sequence import pad_sequences
from keras.models import load_model

class PreprocessQuestions:
    def __init__(self):
        save_option = tf.saved_model.LoadOptions(experimental_io_device='/job:localhost')
        
        self.stop_words = stopwords.words('english')
        self.cnn_model = load_model("./QTag_model", options=save_option)
        self.tokenizer = pickle.load(open("./tokenizer.sav", 'rb'))
        self.mlb = pickle.load(open("./mlb.sav", 'rb'))
        self.lemmatizer = WordNetLemmatizer()

    def lemmatize_words(self, text):
        words = text.split()
        words = [self.lemmatizer.lemmatize(word) for word in words]
        return ' '.join(words)
    
    def getTags(self, s, threshold):
        s = self.lemmatize_words(s)
        s = ' '.join([word for word in s.split() if word not in (self.stop_words)])
        l = []
        l.append(s)

        self.tokenizer.fit_on_texts(l)
        sequences = self.tokenizer.texts_to_sequences(l)
        x_inp = pad_sequences(sequences, maxlen=500)
        pred = self.cnn_model.predict(x_inp)
        for i in range(50):
            if pred[0][i] < threshold:
                pred[0][i] = 0
            else:
                pred[0][i] = 1
        ans = self.mlb.inverse_transform(pred)
        print(ans)
        return ans[0]